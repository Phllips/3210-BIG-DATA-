{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re \n",
    "import nltk\n",
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "from nltk import pos_tag, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Phllips\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://Liam2:Poop@cluster0-shard-00-00-fsjlu.mongodb.net:27017,cluster0-shard-00-01-fsjlu.mongodb.net:27017,cluster0-shard-00-02-fsjlu.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin&retryWrites=true&w=majority\")\n",
    "#connecting to mondb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['assignment1', 'test', 'admin', 'local']\n"
     ]
    }
   ],
   "source": [
    "print(client.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = client.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tweets']\n"
     ]
    }
   ],
   "source": [
    "print(mydb.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsCol = mydb.Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Phllips\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymongo.cursor.Cursor object at 0x000001EB956176A0>\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "cursor2 = tweetsCol.find()\n",
    "print(cursor2)\n",
    "\n",
    "for i in cursor2: #cleaning the text\n",
    "    if 'text' in i:\n",
    "        tweetT = re.sub('[^a-zA-Z]',' ',i['text'])\n",
    "        tweetT = tweetT.lower()\n",
    "        tweetT = tweetT.split()\n",
    "        ps = PorterStemmer()\n",
    "        tweetT = [ps.stem(word) for word in tweetT if not word in set(stopwords.words('english'))]\n",
    "        corpus.append(tweetT)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([('train', 'NN'), ('peopl', 'NN'), ('well', 'RB'), ('enough', 'RB'), ('leav', 'JJ'), ('treat', 'NN'), ('well', 'RB'), ('enough', 'RB'), ('want', 'VBP'), ('richardbranson', 'NN')])\n",
      " list([('friday', 'RB'), ('even', 'RB'), ('welcom', 'VBP'), ('new', 'JJ'), ('mre', 'NN'), ('phd', 'NN'), ('student', 'NN'), ('walk', 'VBP'), ('tour', 'NN'), ('citi', 'NN'), ('intern', 'JJ'), ('student', 'NN'), ('enjoy', 'NN'), ('see', 'VBP'), ('sight', 'JJ'), ('sydney', 'NN'), ('cityofsydney', 'NN'), ('macquarieuniexperi', 'NN'), ('macquari', 'NN'), ('uni', 'JJ'), ('mqintl', 'NN'), ('mqscieng', 'NN')])\n",
      " list([('excit', 'JJ'), ('publish', 'JJ'), ('bpm', 'NN'), ('newslett', 'NN'), ('first', 'RB'), ('one', 'CD'), ('download', 'NN'), ('http', 'NN'), ('tinyurl', 'NN'), ('com', 'NN'), ('ync', 'NN'), ('bpmconf', 'NN'), ('bpm', 'NN')])\n",
      " list([('social', 'JJ'), ('network', 'NN'), ('amplifi', 'JJ'), ('neg', 'JJ'), ('posit', 'NN'), ('great', 'JJ'), ('articl', 'JJ'), ('http', 'NN'), ('washingtonmonthli', 'NN'), ('com', 'NN'), ('magazin', 'NN'), ('januari', 'NN'), ('februari', 'VBP'), ('march', 'NN'), ('fix', 'NN'), ('facebook', 'NN'), ('fix', 'VBP'), ('us', 'PRP'), ('cc', 'VBP'), ('webfound', 'NN')])\n",
      " list([('welcom', 'NN'), ('offici', 'MD'), ('depart', 'VB'), ('comput', 'NN'), ('comput', 'NN'), ('mq', 'VBP'), ('twitter', 'NN'), ('account', 'NN')])\n",
      " list([('watch', 'NN'), ('incred', 'VBD'), ('tedtalk', 'JJ'), ('ibm', 'JJ'), ('scientist', 'NN'), ('bmibruno', 'NN'), ('titl', 'NN'), ('brain', 'NN'), ('keep', 'VB'), ('ai', 'JJ'), ('stay', 'NN'), ('tune', 'NN'), ('fun', 'JJ'), ('end', 'NN'), ('hint', 'NN'), ('look', 'NN'), ('shoe', 'NN'), ('tedatibm', 'NN')])\n",
      " list([('man', 'NN'), ('syndrom', 'NN'), ('help', 'NN'), ('dad', 'VB'), ('use', 'NN'), ('million', 'CD'), ('dollar', 'NN'), ('compani', 'NN'), ('show', 'NN'), ('world', 'NN'), ('peopl', 'NN'), ('learn', 'VBP'), ('disabl', 'NN'), ('capabl', 'NN'), ('amaz', 'NN')])\n",
      " list([('good', 'JJ'), ('person', 'NN'), ('wast', 'JJ'), ('time', 'NN'), ('tri', 'NNS'), ('prove', 'VBP')])\n",
      " list([('start', 'VB'), ('write', 'JJ'), ('bpm', 'JJ'), ('paper', 'NN'), ('one', 'CD'), ('month', 'NN'), ('left', 'VBD'), ('till', 'JJ'), ('abstract', 'JJ'), ('submiss', 'JJ'), ('http', 'NN'), ('bpm', 'NN'), ('web', 'NN'), ('cse', 'NN'), ('unsw', 'JJ'), ('edu', 'NN'), ('au', 'NN'), ('call', 'NN'), ('paper', 'NN'), ('html', 'NN')])\n",
      " list([('final', 'JJ'), ('http', 'NN'), ('deeplearn', 'NN'), ('ai', 'VBP'), ('cours', 'NNS'), ('sequenc', 'VBP'), ('model', 'NN'), ('coursera', 'NN'), ('project', 'NN'), ('build', 'VBP'), ('includ', 'JJ'), ('speech', 'NN'), ('trigger', 'NN'), ('word', 'NN'), ('detect', 'NN'), ('translat', 'JJ'), ('emojif', 'NN'), ('text', 'NN'), ('gener', 'NN'), ('w', 'VBD'), ('rnn', 'JJ'), ('lstm', 'NN'), ('gru', 'NN'), ('word', 'NN'), ('embed', 'VBD'), ('attent', 'JJ'), ('hope', 'NN'), ('fun', 'NN')])\n",
      " list([('mani', 'NN'), ('peopl', 'NN'), ('think', 'VBP'), ('patienc', 'IN'), ('sign', 'NN'), ('weak', 'JJ'), ('think', 'NN'), ('mistak', 'NN'), ('anger', 'NN'), ('sign', 'NN'), ('weak', 'JJ'), ('wherea', 'NN'), ('patienc', 'NN'), ('sign', 'NN'), ('strength', 'NN')])\n",
      " list([('year', 'NN'), ('old', 'JJ'), ('bailey', 'NN'), ('holt', 'NN'), ('preston', 'IN'), ('cope', 'NN'), ('two', 'CD'), ('teen', 'NN'), ('kill', 'VB'), ('kentuckyschoolshoot', 'JJ'), ('th', 'JJ'), ('school', 'NN'), ('shoot', 'NN'), ('day', 'NN'), ('left', 'VBD'), ('januari', 'NN')])\n",
      " list([('name', 'NN'), ('avgi', 'IN'), ('last', 'JJ'), ('time', 'NN'), ('anyon', 'NN'), ('saw', 'VBD'), ('face', 'NN'), ('greec', 'NN'), ('nearli', 'CD'), ('year', 'NN'), ('ago', 'RB')])\n",
      " list([('past', 'IN'), ('past', 'JJ'), ('noth', 'DT'), ('chang', 'NN'), ('futur', 'NN'), ('differ', 'VBP'), ('choos', 'NNS'), ('make', 'VBP'), ('cultiv', 'JJ'), ('vision', 'NN'), ('happier', 'NN'), ('peac', 'NN'), ('futur', 'NNS'), ('make', 'VBP'), ('effort', 'NN'), ('bring', 'NN'), ('time', 'NN'), ('complac', 'JJ'), ('hope', 'NN'), ('lie', 'VBZ'), ('action', 'NN'), ('take', 'VB')])\n",
      " list([('busi', 'NN'), ('process', 'NN'), ('analyt', 'JJ'), ('deal', 'NN'), ('examin', 'NN'), ('larg', 'NN'), ('vari', 'NN'), ('process', 'NN'), ('relat', 'JJ'), ('data', 'NNS'), ('e', 'RB'), ('big', 'JJ'), ('process', 'NN'), ('data', 'NNS'), ('uncov', 'JJ'), ('hidden', 'JJ'), ('pattern', 'NN'), ('unknown', 'JJ'), ('correl', 'NN'), ('market', 'NN'), ('trend', 'NN'), ('custom', 'NN'), ('prefer', 'VBP'), ('use', 'NN'), ('insight', 'NN')])\n",
      " list([('modern', 'JJ'), ('educ', 'JJ'), ('pay', 'NN'), ('littl', 'NN'), ('attent', 'NN'), ('inner', 'NN'), ('valu', 'NN'), ('yet', 'RB'), ('basic', 'JJ'), ('human', 'JJ'), ('natur', 'NN'), ('compassion', 'NN'), ('need', 'VBP'), ('incorpor', 'JJ'), ('compass', 'NN'), ('warm', 'NN'), ('hearted', 'VBD'), ('modern', 'JJ'), ('educ', 'NN'), ('system', 'NN'), ('make', 'VBP'), ('holist', 'NN')])\n",
      " list([('happi', 'JJ'), ('goal', 'NN'), ('habit', 'NN'), ('http', 'JJ'), ('virg', 'NN'), ('j', 'NN'), ('r', 'NN')])\n",
      " list([('way', 'NN'), ('perceiv', 'IN'), ('react', 'JJ'), ('world', 'NN'), ('choic', 'NN'), ('david', 'NN'), ('wallac', 'NN'), ('choos', 'NN'), ('wise', 'NN'), ('chanc', 'NN')])\n",
      " list([('reliv', 'NN'), ('breathtak', 'NN'), ('sydny', 'NN'), ('firework', 'NN'), ('display', 'NN'), ('see', 'VBP'), ('highlight', 'JJ'), ('biggest', 'JJS'), ('firework', 'NN'), ('display', 'NN'), ('ever', 'RB')])\n",
      " list([('sydney', 'NN'), ('firework', 'NN'), ('alway', 'RB'), ('look', 'VBP'), ('amaz', 'JJ'), ('bucket', 'NN'), ('list', 'NN'), ('new', 'JJ'), ('year', 'NN'), ('wish', 'JJ'), ('everyon', 'NN'), ('happi', 'RB'), ('good', 'JJ'), ('health', 'NN')])\n",
      " list([('measur', 'NN'), ('program', 'NN'), ('progress', 'NN'), ('line', 'NN'), ('code', 'NN'), ('like', 'IN'), ('measur', 'NN'), ('aircraft', 'NN'), ('build', 'NN'), ('progress', 'NN'), ('weight', 'VBD'), ('bill', 'NN'), ('gate', 'NN')])\n",
      " list([('today', 'NN'), ('wintersolstic', 'JJ'), ('also', 'RB'), ('shortest', 'JJS'), ('day', 'NN'), ('year', 'NN'), ('solstic', 'JJ'), ('equinox', 'NN'), ('occur', 'VBP'), ('get', 'VB'), ('answer', 'JJR'), ('http', 'NN'), ('go', 'VBP'), ('nasa', 'JJ'), ('gov', 'NN'), ('bg', 'NN'), ('apv', 'NN')])\n",
      " list([('want', 'NN'), ('first', 'JJ'), ('ai', 'JJ'), ('job', 'NN'), ('come', 'VB'), ('intern', 'JJ'), ('run', 'VBN'), ('internship', 'NN'), ('program', 'NN'), ('help', 'NN'), ('peopl', 'VB'), ('complet', 'NN'), ('mooc', 'JJ'), ('start', 'NN'), ('employ', 'NN'), ('ai', 'NN'), ('http', 'NN'), ('land', 'NN'), ('ai', 'VBP'), ('ai', 'CD'), ('internship', 'NN')])\n",
      " list([('one', 'CD'), ('brief', 'NN'), ('histori', 'NN'), ('comput', 'VBD'), ('ever', 'RB'), ('written', 'VBN'), ('piec', 'JJ'), ('perfect', 'JJ'), ('softwar', 'NN'), ('unlik', 'NN'), ('first', 'RB'), ('andi', 'VBZ'), ('hunt', 'NN')])\n",
      " list([('look', 'NN'), ('great', 'JJ'), ('read', 'JJ'), ('enjoy', 'NN'), ('holiday', 'NN'), ('go', 'VBP'), ('wrong', 'JJ'), ('one', 'CD'), ('book', 'NN')])\n",
      " list([('kind', 'NN'), ('photograph', 'NN'), ('turn', 'NN'), ('kid', 'NN'), ('ill', 'VBZ'), ('disabl', 'JJ'), ('superhero', 'NN'), ('sundaymorn', 'NN')])\n",
      " list([('think', 'NN'), ('lot', 'NN'), ('divers', 'NNS'), ('ai', 'VBP'), ('current', 'JJ'), ('stanford', 'NN'), ('group', 'NN'), ('http', 'VBD'), ('stanfordmlgroup', 'JJ'), ('github', 'NN'), ('io', 'NN'), ('peopl', 'VBP'), ('strive', 'JJ'), ('better', 'JJR'), ('increas', 'JJ'), ('divers', 'NNS'), ('ai', 'VBP'), ('need', 'VBP'), ('welcom', 'NNS'), ('everyon', 'VB')])\n",
      " list([('import', 'NN'), ('much', 'RB'), ('long', 'RB'), ('live', 'JJ'), ('whether', 'IN'), ('live', 'JJ'), ('meaning', 'VBG'), ('life', 'NN'), ('mean', 'JJ'), ('accumul', 'JJ'), ('money', 'NN'), ('fame', 'NN'), ('servic', 'JJ'), ('fellow', 'JJ'), ('human', 'JJ'), ('be', 'VB'), ('mean', 'VBN'), ('help', 'NN'), ('other', 'JJ'), ('even', 'RB'), ('least', 'JJS'), ('harm', 'NN')])\n",
      " list([('ever', 'RB'), ('wonder', 'JJR'), ('role', 'NN'), ('senior', 'JJ'), ('pc', 'NN'), ('member', 'NN'), ('gener', 'NN'), ('chair', 'NN'), ('bpm', 'NN'), ('confer', 'VBP'), ('check', 'VB'), ('new', 'JJ'), ('version', 'NN'), ('bpm', 'NN'), ('confer', 'VBP'), ('guidelin', 'NN'), ('http', 'NN'), ('bit', 'NN'), ('ly', 'JJ'), ('nwg', 'NN')])\n",
      " list([('boston', 'NN'), ('dynam', 'VBZ'), ('new', 'JJ'), ('atla', 'NNS'), ('robot', 'VBP')])\n",
      " list([('use', 'NN'), ('forc', 'NN'), ('may', 'MD'), ('control', 'VB'), ('peopl', 'NN'), ('physic', 'JJ'), ('chang', 'JJ'), ('heart', 'NN'), ('mind', 'NN'), ('basi', 'NN'), ('trust', 'NN'), ('friendship', 'NN')])\n",
      " list([('coredb', 'NN'), ('data', 'NNS'), ('lake', 'VBP'), ('servic', 'JJ'), ('http', 'NN'), ('youtu', 'NN'), ('ucon', 'JJ'), ('idrpu', 'NN'), ('via', 'IN'), ('youtub', 'NN')])\n",
      " list([('happi', 'JJ'), ('day', 'NN'), ('cyru', 'VB'), ('great', 'JJ'), ('king', 'NN'), ('persia', 'NN'), ('octob', 'NN'), ('draw', 'NN'), ('made', 'VBD'), ('almost', 'RB'), ('one', 'CD'), ('year', 'NN'), ('ago', 'RB'), ('visit', 'NN'), ('tomb', 'NN')])\n",
      " list([('optic', 'JJ'), ('illus', 'NN'), ('crosswalk', 'NN'), ('aim', 'NN'), ('slow', 'JJ'), ('speedi', 'NN'), ('iceland', 'NN'), ('driver', 'NN')])\n",
      " list([('interest', 'NN'), ('co', 'NN'), ('locat', 'NN'), ('workshop', 'NN'), ('bpm', 'NN'), ('look', 'VBP'), ('call', 'NN'), ('workshop', 'NN'), ('propos', 'NN'), ('http', 'NN'), ('bit', 'NN'), ('ly', 'JJ'), ('gnxuni', 'NN')])\n",
      " list([('chatbot', 'NN'), ('help', 'NN'), ('mental', 'JJ'), ('health', 'NN'), ('great', 'JJ'), ('articl', 'JJ'), ('woebot', 'NN'), ('willknight', 'NN')])\n",
      " list([('figur', 'NN'), ('data', 'NNS'), ('structur', 'NN'), ('code', 'NN'), ('follow', 'VBP'), ('william', 'NN'), ('laeder', 'NN')])\n",
      " list([('learn', 'JJ'), ('play', 'NN'), ('game', 'NN'), ('key', 'JJ'), ('way', 'NN'), ('human', 'JJ'), ('anim', 'NN'), ('build', 'NN'), ('intellig', 'NN'), ('ai', 'VBP'), ('work', 'NN'), ('way', 'NN'), ('http', 'JJ'), ('www', 'NN'), ('topbot', 'NN'), ('com', 'NN'), ('game', 'NN'), ('make', 'VBP'), ('ai', 'JJ'), ('smarter', 'NN'), ('openai', 'NN'), ('starcraft', 'NN'), ('minecraft', 'NN'), ('ml', 'NN')])\n",
      " list([('samsung', 'NN'), ('bought', 'VBD'), ('fridg', 'NNS'), ('make', 'VBP'), ('nois', 'NNS'), ('like', 'IN'), ('jackhamm', 'NN'), ('db', 'NN'), ('custom', 'NN'), ('servic', 'NN'), ('tell', 'VBP'), ('wait', 'RB'), ('six', 'CD'), ('month', 'NN'), ('bs', 'NN'), ('samsungshamesham', 'NN')])\n",
      " list([('hundr', 'NN'), ('million', 'CD'), ('student', 'NN'), ('spend', 'JJ'), ('year', 'NN'), ('school', 'NN'), ('learn', 'VBP'), ('virtual', 'JJ'), ('noth', 'DT'), ('need', 'VBP'), ('better', 'JJR')])\n",
      " list([('failur', 'JJ'), ('fall', 'NN'), ('refus', 'NN'), ('get', 'VBP'), ('chines', 'NNS'), ('proverb', 'NNS')])\n",
      " list([('putin', 'NNS'), ('say', 'VBP'), ('nation', 'NN'), ('lead', 'NN'), ('ai', 'VBP'), ('ruler', 'NN'), ('world', 'NN')])\n",
      " list([('put', 'NN'), ('everyday', 'JJ'), ('object', 'JJ'), ('hand', 'NN'), ('great', 'JJ'), ('teacher', 'JJ'), ('lead', 'NN'), ('magic', 'JJ'), ('moment', 'NN'), ('classroom', 'NN')])\n",
      " list([('may', 'MD'), ('control', 'VB'), ('peopl', 'NN'), ('physic', 'JJ'), ('forc', 'NN'), ('chang', 'NN'), ('heart', 'NN'), ('mind', 'NN'), ('requir', 'NN'), ('trust', 'NN'), ('friendship', 'NN')])\n",
      " list([('congrat', 'NN'), ('dr', 'NN'), ('jemma', 'NN'), ('geoghegan', 'NN'), ('recipi', 'NN'), ('young', 'JJ'), ('tall', 'JJ'), ('poppi', 'NN'), ('scienc', 'NN'), ('award', 'NN'), ('work', 'NN'), ('evolutionari', 'RB'), ('biolog', 'JJ'), ('http', 'NN'), ('macq', 'NN'), ('v', 'NN'), ('fvkq', 'NN')])\n",
      " list([('grow', 'NN'), ('danger', 'NN'), ('slowli', 'JJ'), ('sleepwalk', 'NN'), ('war', 'NN'), ('korean', 'JJ'), ('peninsula', 'NN'), ('reflect', 'NN'), ('today', 'NN'), ('ft', 'VBP')])\n",
      " list([('one', 'CD'), ('brilliant', 'NN'), ('chill', 'NN'), ('thing', 'NN'), ('ever', 'RB'), ('written', 'VBN'), ('nuclear', 'JJ'), ('war', 'NN'), ('late', 'RB'), ('roger', 'NN'), ('fisher', 'NN')])\n",
      " list([('thing', 'NN'), ('enjoy', 'NN'), ('read', 'VBD'), ('good', 'JJ'), ('book', 'NN'), ('read', 'VBP'), ('recommend', 'VB'), ('http', 'JJ'), ('bit', 'NN'), ('ly', 'JJ'), ('wjgolk', 'NN'), ('bookloversday', 'NN')])\n",
      " list([('announc', 'NN'), ('deeplearn', 'NN'), ('ai', 'VBP'), ('deep', 'JJ'), ('learn', 'NN'), ('coursera', 'NN'), ('master', 'NN'), ('deep', 'NN'), ('learn', 'NN'), ('build', 'VBP'), ('career', 'NN'), ('ai', 'NN')])\n",
      " list([('univers', 'NNS'), ('pretti', 'VBP'), ('big', 'JJ'), ('place', 'NN'), ('us', 'PRP'), ('seem', 'VBP'), ('like', 'IN'), ('aw', 'NN'), ('wast', 'JJ'), ('space', 'NN'), ('carl', 'NN'), ('sagan', 'NN')])\n",
      " list([('samsung', 'NN'), ('bought', 'VBD'), ('fridg', 'NNS'), ('make', 'VBP'), ('nois', 'NNS'), ('like', 'IN'), ('jackhamm', 'NN'), ('db', 'NN'), ('custom', 'NN'), ('servic', 'NN'), ('tell', 'VBP'), ('wait', 'RB'), ('six', 'CD'), ('month', 'NN'), ('bs', 'NN'), ('samsungshamesham', 'NN')])\n",
      " list([('samsung', 'NN'), ('bought', 'VBD'), ('fridg', 'NNS'), ('make', 'VBP'), ('nois', 'NNS'), ('like', 'IN'), ('jackhamm', 'NN'), ('db', 'NN'), ('custom', 'NN'), ('servic', 'NN'), ('tell', 'VBP'), ('wait', 'RB'), ('six', 'CD'), ('month', 'NN'), ('bs', 'NN'), ('samsungshamesham', 'NN')])]\n"
     ]
    }
   ],
   "source": [
    "tweettagged = []\n",
    "for i in range(len(corpus)):\n",
    "    tweettagged.append(pos_tag(corpus[i]))  \n",
    "tweettagged = np.array(tweettagged).ravel() #making each entry a list so its easier to iterate through\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keywords = ['NN', 'NNS', 'NNP','NNPS'] #selecting all nouns\n",
    "tweetNouns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bpm', 'newslett', 'download', 'http', 'tinyurl', 'com', 'ync', 'bpmconf', 'bpm']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tweettagged)): ##extracting the nouns from each tweet\n",
    "    tweetNouns.append([x[0] for x in tweettagged[i] if x[1] in keywords])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tweetNouns)): #adding the selected nouns to the a new tweet attribute\n",
    "    mydb.Tweets.update_one({\"Noun keyWords\": {\"$exists\": 0}}, {\"$set\": {\"Noun keyWords\": tweetNouns[i]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
